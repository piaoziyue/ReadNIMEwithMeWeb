---
layout: post
title: "Music communication and related concepts"
tags: embodied
categories: reading
---

## Marc Leman The Routledge companion to embodied music interaction
2017

> Embodied music interaction manifests itself through activities with sounds (listening, playing, dancing), with other people (as in joint action), as well as with music instruments and within the body (as a mediator for music playing).
>
> musical interaction can be conceived as a gym for practicing cultural transmission, empathy, community actions, and solidarity. Finding the neural grounds for a shared understanding between listener and performer, and within a performers’ dyad, and studying how this shared understanding develops in the course of repeated instances should inspire future research.
>
> Inspired by hyper-scanning, a recent theory proposes that the key to mutual understanding in society is the coupling between individuals’ brains (Hasson, Ghazanfar, Galantucci, Garrod, & Keysers, 2012). The theory stems from the assumption that the perceptual system of one brain can be coupled to the motor system of another brain within the same physical environment, an assumption derived from the finding in monkeys of mirror neurons in the ventral premotor cortex, which respond both to action and to action observation (Rizzolatti, Fadiga, Gallese, & Fogassi, 1996). As described by Hasson et al. (2012): “Brain-to-brain coupling is analogous to a wireless communication system in which two brains are coupled via the transmission of a physical signal (light, sound, pressure or chemical compound) through the shared physical environment” (p. 114). The first study conducted on five subjects supporting this theory (Hasson, Nir, Levy, Fuhrmann, & Malach, 2004) introduced an innovative way to analyze the time-series of the fMRI signal, by pairwise inter-subject correlations (ISC) of each voxel time-series, time point by time point (see Figure 27.1). Hence, the time course of each voxel in a given source brain of subject a was used as a predictor of the activation in the corresponding voxel of the target brain of the paired subject b. Results showed that the dynamic course of the neural activity (e.g., in face-specific areas) exhibit pair-wise similarity across participants while watching specific parts of a movie with faces. Nummenmaa et al. (2012) provided further support to the theory by showing that the brains of 16 individuals “tick together” while watching similar emotional events in movie clips.
>

# Embodied Music Cognition and Mediation Technology - Marc Leman
*Involvement is a relationship between a person (henceforth also called a subject) and music. FOcus more on the musical expression*
but take biomechanical energy of the performer into concideration as part of musical intention, part is sound energy and part is haptic energy
> machines may be furnished with tools that become extensions of the human body. 
> these tools may be conceived of as more or less independent agents with which humans can interact at a level in agreement with the assessment of **intentional actions and nonverbal corporeal communication**.

## 1. music experience and 
> fine-grained control over the music performance is missing, and that mediation technology stands between what they want and what they get.
> Transparent technology should thereby give a feeling of non-mediation, a feeling that the mediation technology ‘‘disappears’’ when it is used. Such a technology would then act as a natural mediator for search-and-retrieval purposes as well as for interactive music-making.
> mediation technology is a very challenging problem that cannot be solved by technology alone. It calls for a more general solution in which an overall theory of the human mind, body, and sound is needed. 
> **for improving our involvement with music and our use of music.**: technologies for music mediation may facilitate access to music and, therefore, contribute to a better involvement with music.


### human agent communication
> intentional verbal and nonverbal interaction is an important and useful metaphor in human–machine communication research

> the human body, as a natural mediator between the mental world and the world of physical entities, can be extended with technology, thus allowing a more flexible access to music encoded and stored in machines
>
> Playing a musical instrument is an interactive activity, and the musical instrument can be seen as the technology which mediates between human mind (musical ideas) and physical energy (music as sound).
>
> musical communication involves all senses, and therefore is a multimodal experience, is not new. a central concept of ethnomusicology, in which music and sound are seen as part of a multitude of energies and events having social and cultural signification (Merriam, 1964)
    > Merriam, A.P. and Merriam, V., 1964. The anthropology of music. Northwestern University Press.

> Moreover, even if the music is limited to a single energetic channel such as audio (as in radio, CD, or iPod), then the musical experience can still be said to be a multimodal experience. Music moves the body, evokes emotional responses, and generates associations with spaces and textures.
>
> Music as sound involves all senses, but often music is also embedded in other physical energies that have an impact on how music is experienced
>
> In the early seventeenth century, Florentine humanists introduced the concept of **opere (works)** as a new and strategic attempt to integrate media of expression—such as singing, reciting, movement, and musical accompaniment—in close synergy with each other
>
> The link between **multimodal experiences and multimedia technologies** can be seen as an extension of a long tradition that puts the human body (again) at the center of musical activity, as it is in many nonWestern music cultures.
>
> The connective thread in these developments seems to be the desire to **enhance the expressive power of music**, using technology as a means. the integration of sound with other types of energy can be seen as enhancing the effect of peak experiences, of being immersed within the music
>
> **Micro-integration** : the parameters of musical expressiveness to be extracted from one modality, say sound, and then to be reused in another modality, for example, in computer animation, where it is used to modify the expressive movement of an avatar on a screen (Mancini et al., 2006).
>
> Corporeal articulation: 
>
> through corporeal articulation, multimodal experience of music (through movement, vision, audio) is translated into components of our subjective action-oriented ontology, and vice versa
>
> music interaction is considered in terms of the communication between a musician and a listener, using a musical instrument as mediator.
>
> Studies also show that listeners are capable of capturing important aspects of the intended expressive meaning in music. They may recognize what kind of expressive intention the musician wanted to communicate (Gabrielsson and Juslin, 2003). This finding suggests that the musician can encode particular intentions which the listener can decode. More particularly, these message may relate to something as elusive as expressiveness
>
> how decoding could work as a mechanism, and how the listener may have knowledge of the particular intention that is encoded in the music.

## **A Model of Musical Communication**: 
The model suggests a musical signification practice that is based on the encoding and decoding of patterns of corporeal articulations.
![](/assets/2025-02-22-musical%20communication.png)

encoding and decoding of biomechanical energy allows the communication of intentions

## Model of social music communication, with interaction (1) among performers, (2) from performers to listeners (music-driven interaction), (3) among listeners, and (4) from listeners to performers.
![](/assets/2025-02-22-social%20communication.png)

## Empathy!!
Empathy (inleven in Dutch, Einfu ̈ hlung in German) is the ability to share another person’s feelings or emotions as if they were one’s own (see, e.g., Berthoz and Jorland, 2004).


# Enhancing human-human musical interaction through kinesthetic haptic feedback using wearable exoskeletons: theoretical foundations, validation scenarios, and limitations-2024
One of the primary motivations for human collaborative interaction is the pursuit of reaching goals that typically go beyond the scope of individual capabilities (Jarrassé et al., 2012; Sebanz and Knoblich, 2021). 


# The dynamics of musical participation
Schiavio, A., Maes, P.J. and van der Schyff, D., 2022. The dynamics of musical participation. Musicae Scientiae, 26(3), pp.604-626.

> musical participation—the complex network of interactive dynamics involved in collaborative musical experience
>
> interactive musical agents (i.e., performers) are often conceived of as individual units embedded within a larger system 
(see D'Ausilio et al., 2015; Volpe et al., 2016)

> temporal information in a small ensemble may be coordinated by a leader who is responsible for indicating tempo and phrasing through bodily and sonic cues, 
other kinds of musical information should be actively participate, this especially cause problem for **jazz musician in improvisation**, and also in this process, there is not 
a clear defined leader.

> Walton 2015: emergent patterns of bodily coordination that musicians develop in joint improvisation, highlighting how forms of motor coherence emerge between the interacting agents at multiple time scales, and how this is guided by mutually modulatory self-organizing dynamics across corporeal and sonic dimensions
> Thr peocess: **negotiation of sensorimotor co-regulation** between the performers, which enables the constitution of an evolving musical environment, and that, in turn, shapes the patterns of movement and sound that are enacted as the musical interaction unfolds.
>
> **summary of the dynamics of musical participation**: The theoretical foundation of this research draws upon Dynamical Systems Theory (DST) and Coordination Dynamics, viewing musical interaction as an open, non-equilibrium dynamical system characterized by continuous reciprocal causation involving multimodal, bodily-coupled feedback loops. The proposed Augmented Transmission Model (ATM) is based on these principles, aiming to technologically enhance multimodal bodily sensation transmission, thus facilitating more efficient mutual understanding between interacting agents. Additionally, the research explores the possibility of conceptualizing this mutual understanding as an emergent property arising from these interactions.
>
> A description of the tension between first- and third-person perspectives in musical and scientific literature can be found in Leman’s Embodied music cognition and mediation technology (2007). Here, Leman also suggests that interaction is central to second-person approaches: “second-person descriptions are used to show, express, and articulate the private experience from one subject to another. They imply a ‘me-to-you’ relationship” (p. 82). As this level of analysis comprises “non-verbal articulations as well as verbal descriptions” (p. 82), models informed by DST could build on such an integrative account to examine the behavioral, linguistics, and emotional features of the ongoing interactive process in more detail (see also de Bruin et al., 2012; Gnisci et al., 2008).